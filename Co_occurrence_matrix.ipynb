{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUkN2j4tAfT7SWjr+WisPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeHoonKOR/NLP/blob/Colab/Co_occurrence_matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "def buildDict(docs):\n",
        "    doc_tokens = []     # python list\n",
        "    for doc in docs:\n",
        "        delim = re.compile(r'[\\s,.]+')\n",
        "        tokens = delim.split(doc.lower())\n",
        "        tokens = [t for t in tokens if t not in sw] \n",
        "        if tokens[-1] == '' :   tokens = tokens[:-1] \n",
        "        doc_tokens.append(tokens)\n",
        "\n",
        "    vocab = FreqDist(np.hstack(doc_tokens))\n",
        "    vocab = vocab.most_common()\n",
        "    word_to_id = {word[0] : id for id, word in enumerate(vocab)}\n",
        "    id_to_word = {id : word[0] for id, word in enumerate(vocab)}\n",
        "    corpus = np.array([id for id, _ in enumerate(vocab)])\n",
        "    return doc_tokens, corpus, word_to_id, id_to_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QuL7c999fXO",
        "outputId": "439d3704-7d0b-4524-91a6-bc0bb20e0fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "with open('/content//sample_data/bts_korean.txt', 'r') as f:\n",
        "    documents = [line.strip() for line in f.readlines() if line.strip()]\n",
        "for id, doc in enumerate(documents):\n",
        "    print('[{}] : {}...'.format(id, doc[:30]))\n",
        "\n",
        "doc_tokens, corpus, word_to_id, id_to_word = buildDict(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go2-Rsy_9ltV",
        "outputId": "d823bd3f-a068-4609-d8a2-a2530d69d81b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] : 방탄복이 총알을 막아내는 것처럼, 살아가는 동안 힘든 ...\n",
            "[1] : 2013년 방탄소년단은 《2 COOL 4 SKOOL》을...\n",
            "[2] : 현재까지 방탄소년단은 전세계에서 3,000만 장 가량의...\n",
            "[3] : 방탄소년단은 SNS를 통한 팬들과의 소통이 활발하여 2...\n",
            "[4] : 빅히트 엔터테인먼트의 대표이자 프로듀서인 방시혁은 20...\n",
            "[5] : 2013년...\n",
            "[6] : 2013년의 방탄소년단 ....\n",
            "[7] : 방탄소년단은 데뷔를 앞둔 2013년 5월 20일, 직접...\n",
            "[8] : 2014년...\n",
            "[9] : 2014년 3월 공연 중인 방탄소년단...\n",
            "[10] : 2014년 1월 16일 경희대학교 평화의 전당에서 열린...\n",
            "[11] : 2015년...\n",
            "[12] : 2014년 11월 17일 인천 한류 콘서트에서의 방탄소...\n",
            "[13] : 2015년 1월 15일 방탄소년단은 중국 북경 완스다 ...\n",
            "[14] : 방탄소년단은 2015년 10월 15일 유럽 최대 음악 ...\n",
            "[15] : 2016년...\n",
            "[16] : 2016년 5월 7일 화양연화 프레스 컨퍼런스에 참석한...\n",
            "[17] : 2016년 1월 14일 방탄소년단은 올림픽공원 체조경기...\n",
            "[18] : 2016년 11월 16일 아시아 아티스트 어워즈에 참석...\n",
            "[19] : 이후 6월부터 8월까지 대만과 마카오, 중국(난징, 베...\n",
            "[20] : 2017년...\n",
            "[21] : 2017년 1월 14일 골든디스크 어워드에 참석한 방탄...\n",
            "[22] : BTS는 2017년 1월 13일 경기도 일산 킨텍스에서...\n",
            "[23] : 2017년 11월 19일 아메리칸 뮤직 어워드에 참석한...\n",
            "[24] : 2017년 9월 18일 방탄소년단은 다섯 번째 미니 앨...\n",
            "[25] : 2017년 11월 13일 방탄소년단의 트위터 코리아 공...\n",
            "[26] : 2018년...\n",
            "[27] : 2018년 10월 24일 방탄소년단...\n",
            "[28] : 방탄소년단은 2018년 1월 10일과 11일 경기도 일...\n",
            "[29] : 2018년 12월 1일 멜론 뮤직 어워드에 참석한 방탄...\n",
            "[30] : 방탄소년단은 2018년 4월 5일 일본 세 번째 정규 ...\n",
            "[31] : 2019년...\n",
            "[32] : 2019년 1월 15일 서울가요대상에서 방탄소년단...\n",
            "[33] : 2019년 2월 11일, 방탄소년단은 제61회 그래미 ...\n",
            "[34] : 2월 25일에는 아미피디아 (ARMYPEDIA) 'AR...\n",
            "[35] : 월드투어 《LOVE YOURSELF: SPEAK YOU...\n",
            "[36] : 10월 18일,《MAP OF THE SOUL : PER...\n",
            "[37] : 2020년...\n",
            "[38] : 2020년 1월 17일, 방탄소년단은 선 공개곡 〈Bl...\n",
            "[39] : 8월 21일, 방탄소년단은 디지털 싱글 〈Dynamit...\n",
            "[40] : 2021년...\n",
            "[41] : 2021년 3월 15일, 미국에서 열린 제63회 그래미...\n",
            "[42] : 12월 10일, 미국 스케줄을 끝 마치고 두번째 장기휴...\n",
            "[43] : 2022년...\n",
            "[44] : 2022년 3월 10일부터 3월 13일까지 서울에서 국...\n",
            "[45] : 6월 2일 국내 컴백을 앞두고 있다....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "    '''동시발생 행렬 생성\n",
        "    :param corpus: 말뭉치(단어 ID 목록)\n",
        "    :param vocab_size: 어휘 수\n",
        "    :param window_size: 윈도우 크기(윈도우 크기가 1이면 타깃 단어 좌우 한 단어씩이 맥락에 포함)\n",
        "    :return: 동시발생 행렬\n",
        "    '''\n",
        "    corpus_size = len(corpus)\n",
        "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "\n",
        "    for idx, word_id in enumerate(corpus):\n",
        "        for i in range(1, window_size + 1):\n",
        "            left_idx = idx - i\n",
        "            right_idx = idx + i\n",
        "\n",
        "            if left_idx >= 0:\n",
        "                left_word_id = corpus[left_idx]\n",
        "                co_matrix[word_id, left_word_id] += 1\n",
        "\n",
        "            if right_idx < corpus_size:\n",
        "                right_word_id = corpus[right_idx]\n",
        "                co_matrix[word_id, right_word_id] += 1\n",
        "\n",
        "    return co_matrix"
      ],
      "metadata": {
        "id": "d6fUnhkB9x_v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ppmi(C, verbose=False, eps = 1e-8):\n",
        "    '''PPMI(점별 상호정보량) 생성\n",
        "    :param C: 동시발생 행렬\n",
        "    :param verbose: 진행 상황을 출력할지 여부\n",
        "    :return:\n",
        "    '''\n",
        "    M = np.zeros_like(C, dtype=np.float32)\n",
        "    N = np.sum(C)\n",
        "    S = np.sum(C, axis=0)\n",
        "    total = C.shape[0] * C.shape[1]\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(C.shape[0]):\n",
        "        for j in range(C.shape[1]):\n",
        "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
        "            M[i, j] = max(0, pmi)\n",
        "\n",
        "            if verbose:\n",
        "                cnt += 1\n",
        "                if cnt % (total//100 + 1) == 0:\n",
        "                    print('%.1f%% 완료' % (100*cnt/total))\n",
        "    return M"
      ],
      "metadata": {
        "id": "upzFPLoK90n3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "print('동시발생행렬 계산')\n",
        "C = create_co_matrix(corpus, vocab_size, window_size)\n",
        "W = ppmi(C)\n",
        "\n",
        "print(C[0,:10])\n",
        "print(W[0, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEJwNNvi93Jr",
        "outputId": "e0c04096-d80f-4bcc-99f6-47a09f93ca06"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "동시발생행렬 계산\n",
            "[0 1 1 0 0 0 0 0 0 0]\n",
            "[ 0.       10.837365 10.422328  0.        0.        0.        0.\n",
            "  0.        0.        0.      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.extmath import randomized_svd\n",
        "wordvec_size = 100\n",
        "U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)"
      ],
      "metadata": {
        "id": "nOHNGTkc98H_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "\n",
        "    if query not in word_to_id:\n",
        "        print('{}를 찾을 수 없음.'.format(query))\n",
        "        return\n",
        "        \n",
        "    word_vector = np.array(word_matrix[word_to_id[query]]) #쿼리단어 벡터 추출\n",
        "    word_vector = word_vector.reshape(1, -1) #cosine_similarity 위해 벡터 형상 조정\n",
        "    sim = cosine_similarity(word_vector, word_matrix)\n",
        "    sim = sim[0] #벡터 형상조정([[]] --> [])\n",
        "    sim = [(id, cos) for id, cos in enumerate(sim)] #id, 유사도쌍으로 정리\n",
        "    sim = sorted(sim, key=lambda x: x[1], reverse=True) #유사도 높은 순 정렬\n",
        "\n",
        "    return sim[1:top+1]"
      ],
      "metadata": {
        "id": "lE-mm3b4-D-f"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank = most_similar('월드', word_to_id, id_to_word, U)\n",
        "for r in rank:\n",
        "    print(id_to_word[r[0]], r[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVf25FQW-F-x",
        "outputId": "af76ab41-5432-494c-ce1d-6db4a87916e9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "무대에 0.99016315\n",
            "15일 0.98953784\n",
            "참석한 0.96215606\n",
            "episode 0.9586951\n",
            "공개했다 0.91906416\n"
          ]
        }
      ]
    }
  ]
}